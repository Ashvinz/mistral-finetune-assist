# ðŸ¤– Mistral AI Assistant â€” Fine-tuned with Unsloth ðŸ”¥

ðŸš€ One-shot fine-tuning of [Mistral-7B](https://huggingface.co/mistralai/Mistral-7B-v0.1) using [Unsloth](https://github.com/unslothai/unsloth) â€” blazing fast, memory-efficient, and fully open-source!  
ðŸŽ¯ Built to create your **own smart AI assistant**, trainable in minutes, and deployable anywhere (Hugging Face, local, or cloud).

---
- âœ… Cloning the repo
- âœ… Cleaning metadata widgets issues
- âœ… Running in Jupyter or Colab safely

---
## ðŸ“Œ Features
- âœ… Single `.ipynb` file to **train & upload to Hugging Face**
- âœ… Based on `unsloth/mistral-7b-bnb-4bit`
- âœ… Instruction tuning format (prompt + response)
- âœ… Hugging Face integration (`push_to_hub`)
- âœ… Customizable for any task (chatbot, Q&A, support bot)

---

## ðŸ§  Model Info

| Property       | Value                                  |
|----------------|----------------------------------------|
| Base Model     | `unsloth/mistral-7b-bnb-4bit`          |
| Trainer        | ðŸ¤— `transformers.Trainer`              |
| Fine-tuning    | LoRA + 4-bit quantization              |
| Use case       | Chat Assistant / Q&A / Task Agent      |
| Hugging Face   | [[aswin/mistral-ai-assist](https://huggingface.co/Aswinkumarr/Finetuned_mistral) *(after upload)* |

---

## ðŸ§ª Run Notebook

1. Clone the repo:
```bash
git clone https://huggingface.co/Aswinkumarr/Finetuned_mistral
cd Finetuned_mistral
